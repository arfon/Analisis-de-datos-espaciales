@book{Fischer2014,
   abstract = {The Handbook of Regional Science is a multi-volume reference work providing a state-of-the-art knowledge on regional science composed by renowned scientists in the field. The Handbook is intended to serve the academic needs of graduate students, and junior and senior scientists in regional science and related fields, with an interest in studying local and regional socio-economic issues. The multi-volume handbook seeks to cover the field of regional science comprehensively, including areas such as regional housing and labor markets, regional economic growth, innovation and regional economic development, new and evolutionary economic geography, location and interaction, the environment and natural resources, spatial analysis and geo-computation as well as spatial statistics and econometrics.},
   author = {Manfred M. Fischer and Peter Nijkamp},
   doi = {10.1007/978-3-642-23430-9},
   journal = {Handbook of Regional Science},
   title = {Handbook of regional science},
   year = {2014},
}

@article{Chasco2003,
   abstract = {El objetivo fundamental de esta tesis consiste en proponer la predicción\nde datos espaciales como parte de la econometría espacial, a partir de\nuna metdología fundamentada en instrumentos exploratorios y confirmatorios\npropios de esta disciplina, En concreto, se desarrolla una subdisciplina\nde la predicción espacial, denominada predicción-extrapolación espacial,\ndistinta del método geoestadístico de interpolación espacial, entendida\ncomo el conjunto de métodos inferenciales destinados a obtener datos microterritoriales\na partir de información espacial agregada.\n\nLa consecución de este objetivo general exige una presentación y sistematización\ndel conjunto de técnicas de análisis exploratorio y confirmatorio de la\neconometría espacial, realizada en el cuerpo central de esta obra, con\nla ayuda de un capítulo completo y actualizando de Bibliografía, así como\nde unos Anexos, que amplían algunas ideas sin romper el hilo de la exposición.\n\nLa metodología propuesta se evalúa a través de un ejercicio de predicción-extrapolación\nde la renta familiar disponible de los municipios de la Comundiad de Madrid,\nen el que se hacen confluir tanto la utilización de técnicas de econometría\nespacial (a través de un "software" adecuado), como la experiencia de la\nautora en análisis microterritoriales, como Directora A. Del Área de Economía\nEspacial Microterritorial del Instituto Lawrence R. Klein (Universidad\nAutónoma de Madrid), co-dirigido por D. José Vicéns Otero, director de\nesta tesis.\n\nDado el interés y el cierto desconocimiento que aún pesa sobre el tema\nde la econometría espacial, esta tesis se plantea también, como objetivo,\nser de utilidad para todos los investigadores sociales interesados en el\nanálisis territorial, en cualquiera de sus formas, así como contribuir,\nen la medida de los posible, a la difusión de las técnicas de econometría\nespacial en nuestro país, sobre todo en el ámbito de los estudios},
   author = {Coro Chasco},
   issue = {April 2003},
   journal = {Consejería de Economía e Innovación Tecnológica},
   title = {Econometría espacial aplicada a la predicción-extrapolación de datos microterritoriales},
   year = {2003},
}

@book{Lovelace2019,
   abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 Å for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
   author = {Robin Lovelace and Jakub Nowosad and Jannes Muenchow},
   doi = {10.1201/9780203730058},
   journal = {Geocomputation with R},
   title = {Geocomputation with R},
   year = {2019},
}

@article{Tennekes2018,
   abstract = {Thematic maps show spatial distributions. The theme refers to the phenomena that is shown, which is often demographical, social, cultural, or economic. The best known thematic map type is the choropleth, in which regions are colored according to the distribution of a data variable. The R package tmap offers a coherent plotting system for thematic maps that is based on the layered grammar of graphics. Thematic maps are created by stacking layers, where per layer, data can be mapped to one or more aesthetics. It is also possible to generate small multiples. Thematic maps can be further embellished by configuring the map layout and by adding map attributes, such as a scale bar and a compass. Besides plotting thematic maps on the graphics device, they can also be made interactive as an HTML widget. In addition, the R package tmaptools contains several convenient functions for reading and processing spatial data.},
   author = {Martijn Tennekes},
   doi = {10.18637/jss.v084.i06},
   issn = {15487660},
   journal = {Journal of Statistical Software},
   title = {Tmap: Thematic maps in R},
   volume = {84},
   year = {2018},
}

@book{Wickham2016,
   abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible. Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You’ll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you’ve learned along the way.},
   author = {Hadley Wickham and Garrett Grolemund},
   issn = {0163-5700},
   journal = {O'Rielly},
   title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
   year = {2016},
}

@webpage{AnselinMorrison2018,
   abstract = {This notebook covers the functionality of the Basic Mapping section of the GeoDa workbook. We refer to that document for details on the methodology, references, etc. The goal of these notes is to approximate as closely as possible the operations carried out using GeoDa by means of a range of R packages.

The notes are written with R beginners in mind, more seasoned R users can probably skip most of the comments on data structures and other R particulars. Also, as always in R, there are typically several ways to achieve a specific objective, so what is shown here is just one way that works, but there often are others (that may even be more elegant, work faster, or scale better).

For this notebook, we will continue to use the socioeconomic data for 55 New York City sub-boroughs from the GeoDa website.},
   author = {Luc Anselin and Grant Morrison},
   journal = {Tutorials. R Spatial Workshop Notes. Introduction to Spatial Data Science.},
   month = {9},
   title = {Basic Mapping. R Notes.},
   year = {2018},
}

@article{Peng2015,
   abstract = {This book brings the fundamentals of R programming to you, using the same material developed as part of the industry-leading Johns Hopkins Data Science Specialization. The skills taught in this book will lay the foundation for you to begin your journey learning data science.},
   author = {Roger D. Peng},
   doi = {10.1073/pnas.0703993104},
   issn = {1467-9280},
   journal = {The R Project; R Foundation},
   title = {R Programming for Data Science},
   year = {2015},
}

@article{Croarkin2014,
   abstract = {The NIST/SEMATECH e-Handbook of Statistical Methods1, is a Web-based book whose goal is to help scientists and engineers incorporate statistical methods into their work as efficiently as possible. Ideally it will serve as a reference that will help scientists and engineers design their own experiments and carry out the appropriate analyses when a statistician is not available to help. It is also hoped that it will serve as a useful educational tool that will help users of statistical methods and consumers of statistical information better understand statistical procedures and their underlying assumptions and more clearly interpret scientific and engineering results stated in statistical terms.},
   author = {C Croarkin and P Tobias},
   journal = {Retrieved January},
   title = {NIST/SEMATECH e-handbook of statistical methods},
   volume = {1},
   year = {2014},
}

@webpage{Anselin2020,
   abstract = {Explore the spatial weights functionality in GeoDa},
   author = {Luc Anselin},
   journal = {GeoDa Workbook.},
   month = {10},
   title = {Contiguity-Based Spatial Weights.},
   url = {https://geodacenter.github.io/workbook/4a_contig_weights/lab4a.html#principle},
   year = {2020},
}

@article{Anselin1995,
   abstract = {The capabilities for visualization, rapid data retrieval, and manipulation in geographic information systems (GIS) have created the need for new techniques of exploratory data analysis that focus on the "spatial" aspects of the data. The identification of local patterns of spatial association is an important concern in this respect. In this paper, I outline a new general class of local indicators of spatial association (LISA) and show how they allow for the decomposition of global indicators, such as Moran's I, into the contribution of each observation. The LISA statistics serve two purposes. On one hand, they may be interpreted as indicators of local pockets of nonstationarity, or hot spots, similar to the Gi and G*i statistics of Getis and Ord (1992). On the other hand, they may be used to assess the influence of individual locations on the magnitude of the global statistic and to identify "outliers," as in Anselin's Moran scatterplot (1993a). An initial evaluation of the properties of a LISA statistic is carried out for the local Moran, which is applied in a study of the spatial pattern of conflict for African countries and in a number of Monte Carlo simulations. 1995 The Ohio State University},
   author = {Luc Anselin},
   doi = {10.1111/j.1538-4632.1995.tb00338.x},
   issn = {15384632},
   issue = {2},
   journal = {Geographical Analysis},
   title = {Local Indicators of Spatial Association-LISA},
   volume = {27},
   year = {1995},
}

@article{Lovelace2014,
   abstract = {This tutorial is an introduction to spatial data in R and map making with R's `base' graphics and the popular graphics package ggplot2. It assumes no prior knowledge of spatial data analysis but prior understanding of the R command line would be beneficial. For people new to R, we recommend working through an `Introduction to R' type tutorial, such as "A (very) short introduction to R" (Torfs and Brauer, 2012) or the more geographically inclined "Short introduction to R" (Harris, 2012). Building on such background material, the following set of exercises is concerned with specific functions for spatial data and visualisation. It is divided into five parts: *Introduction, which provides a guide to R's syntax and preparing for the tutorial *Spatial data in R, which describes basic spatial functions in R *Manipulating spatial data, which includes changing projection, clipping and spatial joins *Map making with ggplot2, a recent graphics package for producing beautiful maps quickly *Taking spatial analysis in R further, a compilation of resources for furthering your skills An up-to-date version of this tutorial is maintained at https://github.com/Robinlovelace/Creating-maps-in-R and the entire tutorial, including the input data can be downloaded as a zip file, as described below. The entire tutorialwas written in RMarkdown, which allows R code to run as the document compiles. Thus all the examples are entirely reproducible. Suggested improvements welcome - please fork, improve and push this document to its original home to ensure its longevity. The tutorial was developed for a series of Short Courses put on by the National Centre for Research Methods, via the TALISMAN node (see geotalisman.org).},
   author = {Robin Lovelace and James Cheshire},
   issue = {03},
   journal = {National Centre for Research Methods Working Papers},
   title = {Introduction to visualising spatial data in R},
   volume = {14},
   year = {2014},
}

@book{Montgomery2012,
   abstract = {Regression analysis is one of the most widely used techniques for analyzing multifactor data. Its broad appeal and usefulness result from the conceptually logical process of using an equation to express the relationship between a variable of interest (the response) and a set of related predictor variables. Regression analysis is also interesting theoretically because of elegant underlying mathematics and a well - developed statistical theory. Successful use of regression requires an appreciation of both the theory and the practical problems that typically arise when the technique is employed with real - world data. This book is intended as a text for a basic course in regression analysis. It contains the standard topics for such courses and many of the newer ones as well. It blends both theory and application so that the reader will gain an understanding of the basic principles necessary to apply regression model - building techniques in a wide variety of application environments. The book began as an outgrowth of notes for a course in regression analysis taken by seniors and fi rst - year graduate students in various fi elds of engineering, the chemical and physical sciences, statistics, mathematics, and management. We have also used the material in many seminars and industrial short courses for professional audiences. We assume that the reader has taken a fi rst course in statistics and has familiarity with hypothesis tests and confi - dence intervals and the normal, t , ?? 2 , and F distributions. Some knowledge of matrix algebra is also necessary. The computer plays a signifi cant role in the modern application of regression. Today even spreadsheet software has the capability to fi t regression equations by least squares. Consequently, we have integrated many aspects of computer usage into the text, including displays of both tabular and graphical output, and general discussions of capabilities of some software packages. We use Minitab�, JMP�, SAS�, and R for various problems and examples in the text. We selected these packages because they are widely used both in practice and in teaching regression and they have good regression. Many of the homework problems require software for their solution. All data sets in the book are available in electronic form from the publisher. The ftp site ftp://ftp.wiley.com/public/sci_tech_med/introduction_linear_ regression hosts the data, problem solutions, PowerPoint fi les, and other material related to the book.},
   author = {Montgomery. Douglas C. and Peck. Elizabeth A. and Vining. G. Geoffrey},
   issn = {03067734},
   issue = {2},
   journal = {A JOHN WILEY & SONS, INC., PUBLICATION},
   title = {Introduction to Linear Regression Analysis, Fifth Edition},
   volume = {81},
   year = {2012},
}

@webpage{JHU2020,
   author = {John Hopkins University},
   journal = {Data scientit's tool box},
   month = {4},
   title = {Types of data science questions},
   year = {2020},
}

@webpage{Dalpiaz2022,
   author = {David Dalpiaz},
   title = {Applied Statistics with R},
   url = {http://daviddalpiaz.github.io/appliedstats/},
}

@book{Gujarati2011,
   abstract = {This book covers some essential topics of econometrics. It covers from single regression to multiple regression. The second part of the book talks about how to detect a violation of assumptions (multicollinearity, heteroscedasticity, autocorrelation, model specification) made for running multiple regression and what the remedies are. The third part deals with three topics, including (a) regression on dummy variables, (b) regression on dummy dependent variables, (c) autoregressive and distributed lag models. The last part deals with simultaneous-equation model.},
   author = {Damodar Gujarati and N Dawn C. Porter},
   journal = {Basic Econometrics},
   title = {Econometria Basica},
   year = {2011},
}


@book{Elhorst2006,
   abstract = {This book provides an overview of three generations of spatial econometric models: models based on cross-sectional data, static models based on spatial panels and dynamic spatial panel data models. The book not only presents different model specifications and their corresponding estimators, but also critically dis- cusses the purposes for which these models can be used and how their results should be interpreted. Special attention is paid to the interpretation of spatial spillover effects. Several of these models are illustrated using well-known datasets. Furthermore, Matlab routines are provided with which the results reported in the book can be replicated and with which researchers can run their own empirical problems.},
   author = {J. Paul Elhorst},
   journal = {Handbook of Spatial Statistics},
   title = {Spatial Econometrics: From Cross Sectional Data to Spatial Panels},
   year = {2006},
}

@book{Anselin2014,
   abstract = {This book is the definitive user's guide to the spatial regression functionality in the software packages GeoDa and GeoDaSpace, as well as the spreg module in the PySAL library --all developed at the GeoDa Center for Geospatial Analysis and Computation. The book provides the techniques to test for and estimate spatial effects in linear regression models, addressing both spatial dependence (spatial autoregressive models) as well as spatial heterogeneity (spatial regimes models). The book also serves as an introduction and a practical guide to spatial econometrics in that it covers the methodological principles and formal results that underlie the various estimation methods, test procedures and model characteristics computed by the software. While the classical maximum likelihood estimation is included, the book's coverage emphasizes modern techniques based on the principle of generalized method of moments (GMM).},
   author = {Luc Anselin and Sergio J Rey},
   journal = {GeoDa Press LLC},
   title = {Modern Spatial Econometrics in Practice: A Guide to GeoDa, GeoDaSpace and PySAL},
   year = {2014},
}

@book{Anselin2005,
   author = {Luc Anselin},
   edition = {1},
   month = {5},
   publisher = {Center for Spatially Integrated Social Science},
   title = {Exploring Spatial Data with GeoDaTM : A Workbook},
   year = {2005},
}
